# Redis集群(Redis Cluster)

### 注: Redis集群需要Redis3.0及以上版本

---

更详细的信息可以参照

[Redis Cluster 添加/删除 完整折腾步骤](http://blog.51cto.com/hsbxxl/1965706),

[Redis集群官方教程](https://redis.io/topics/cluster-tutorial)

---
 
 ## 数据分区及优点
 数据分区(数据分片)是集群最核心的功能，集群是将数据分散到多个节点：
  
  * 突破Redis单机内存大小的限制，有效的规避由于数据量过大导致的单机内存溢出的问题，数据存储容量大大增加
    * 单机内存过大，bgsave 和 bgrewriteaof 的fork操作可能导致主进程阻塞，主从环境下主机切换时可能导致节点长时间无法提供服务，全量复制阶段主节点的复制缓冲区可能出现溢出问题。 
  * 每个主节点都可以提供对外的读写服务器，可以极大的提高应用的响应能力
  * 集群通过自动故障转移来实现高可能的效果，当任意一个节点发生故障时，集群依然可以提供对外服务。（单一节点宕机不会影响服务的正常使用，与哨兵类似，但是是通过应用漂移而非主从切换实现的）

---

## 集群的搭建
 #### 使用Redis命令搭建
 
 集群的搭建主要分为四步：
 > * **启动节点：** 将节点以集群模式启动，启动的各个节点单独独立。
 > * **节点握手：** 让独立的节点连成统一的网络
 > * **分配槽：** 将对应的槽分配给主节点（16384）
 > * ***指定主从关系：*** 为从节点指定主节点 （最后一步是为了实现哨兵模式，主从依赖实现更优的高可用服务）

 ##### 启动节点
 集群的节点启用与正常redis启用完全相同，只需要将对应的配置文件改成集群模式即可
 ``` conf
 # redis.conf 
 # 启用集群的核心配置
 port 7000
 cluster-enabled yes
 cluster-config-file "node-7000.conf"
 logfile "log-70000.log"
 dbfilename "dump-7000.rdb"
 daemonize yes
 ```

 其中集群的两个最主要的配置为cluster-*。

 **cluster-enabled**：Redis实例可以分为单机模式(standalone)和集群模式(cluster)，该配置设置使Redis以集群模式启动

 Redis启动后，可以执行info server命令来查看Redis的模式
 ``` info
 redis_mode:cluster 集群模式
 redis_mode:standalone 单机模式
 ```
**cluster-config-file**：该参数指定了运行过程中，动态维护的配置文件的位置。当集群详细发生变化的时候(增减节点),集群内所有节点都会将最近的集群信息更新到该配置文件中。当该节点以集群模式重新启动的时候，会重新读取配置文件，获取集群信息并将自己加入到集群中。

节点启动后，通过cluster nodes命令```redis-cli -p 7000 cluster nodes ```可以查看该节点的情况。会返回如下信息。
``` 
节点ID(由40个16进制字符串组成)：port myself,master - 0 0 0 connected
```
节点ID会在集群初始化的时候创建一次，然后保存到刚刚上文提到的集群配置文件中，以后会优先读取集群配置文件中的id

##### 节点握手

节点启动后是互相独立的，互相并不知道其他节点的存在；需要通过节点握手的方式，将各个独立的节点汇聚成一个统一的网络。

节点握手使用 ```redis-cli -p 7000 cluster meet {ip} {port} ``` 命令来实现。

之后执行 ``` redis-cli -p 7000 cluster nodes ``` 就可以看到另外一个节点的存在

##### 分配槽
槽是Redis集群中用来实现数据分区，同时做数据管理和数据迁移的基本单位。Redis集群固定有16384个槽。

需要为数据库中所有16384个槽都分配节点，只有所有的槽都分配了节点，集群才能正式生效（ok），一旦任意有一个槽没有分配节点，则集群就将处于下线状态（fail）。

使用``` redis-cli -p 7000 cluster info ``` 可以查看集群状态,可以看到如下的结果

``` info
cluster_state:fail #集群的状态
cluster_slots_assigned:0 #已分配的槽数量
```

使用```redis-cli -p 7000 cluster addslots {startlots,endlots} ```为指定的主节点来分配槽。将 0~16383 全部分配完成后，再执行cluster info后可以看到一下状态
``` info
cluster_state:ok #集群成功
cluster_slots_assigned:16384 #已分配的槽数量
```

##### _指定主从关系_
集群的主从关系不再使用slaveof，而应该使用cluster replicate来指定主从关系。
```
redis-cli -p 8000(从节点) cluster replicate 主节点ID
```

 ###### 至此，集群搭建完毕

---

#### 使用Ruby脚本搭建集群
Redis 提供了Ruby脚本来实现自动化集群搭建，{REDIS_HOME}/src 目录下可以找到redis-trib.rb 文件

##### 安装Ruby环境
windows和linux安装方法不同
##### 启动节点
与上文启动节点方法完全相同
##### 搭建集群
redis-trib.rb 脚本提供了若干命令，可以参照[redis cluster管理工具redis-trib.rb详解](https://blog.csdn.net/huwei2003/article/details/50973967)，其中create是用来搭建集群的。
``` sh
./redis-trib.rb create --replicate 1 {ip:port}s
```
其中replicate 1 指的是每个主节点有一个从节点；{ip:port}是对应redis服务器的ip和端口，中间使用空格分割。

使用该命令创建集群的时候，需要通过如下检查：
 * 要求主从节点之间中不能包含任何槽和数据
 * 检查传入的master节点数量，数量必须大于等于3才能组成集群

检查通过后脚本会给出创建集群的计划，验证无误后输入yes就可以创建一个集群了

 ###### 至此，集群搭建完毕

 ---

 ## 集群方案设计 
 
**设计集群方案时，至少需要考虑一下因素**
 * **高可用**：根据[故障转移的原理](#cluster-principle)，需要至少3个节点才能完成故障转移(这也是Ruby对master数量验证的主要原因)；每一个主节点最好至少配备一个从节点，防止主节点宕机后无法完成剩余节点的故障转移；另外每一个节点都分属不同的物理机，防止多节点同时宕机。
 * **数据量和访问量**:估算应用的数据量和总访问量，结合每个主节点的容量和能承受的访问量（可以使用benchmark来估计），同时最好留有冗余。
 * **尽量避免大集群**：Redis官方给出的节点最大数量为1000，主要是考虑节点之间通信带来的性能消耗问题。在实际应用过程中，应尽量避免大集群，如果节点数量不足以满足数据量及访问量的需求时，可以考虑
    * 业务分割，使用微服务来将大集群转换为小集群
    * 减少不必要的缓存数据，避免对Redis的频繁访问，降低数据量和网络通信的性能损耗
    * 调整数据过期策略，均衡数据过期及网络通信之间的性能问题
* **适度冗余**：考虑到业务增长，可适当增加节点数量，但不应过大

---

<span id="cluster-principle"></span>
## 集群的基本原理

### 数据分区方案
数据分区主要有顺序分区，哈希分区等。由于哈希分区具有天然的随机性，应用广泛；Redis集群的分区方案就是哈希分区的一种。

哈希分区的基本思想是:基于数据的特征值(Redis中使用的是数据的Key)进行哈希，然后根据哈希值来决定数据的落点。

常见的哈希分区包括：哈希取余分区，一致性分区，带虚拟节点的一致性哈希分区等方案。

>衡量数据分区方法好坏的主要因素为以下两个
 >* 数据分布是否均匀
 >* 增删节点对数据分布的影响及数据调整的成本。

对于哈希分布来说，数据是否分布均匀取决于哈希算法和对应关键值(Key)的哈希计算结果，所以第一点不在衡量哈希算法的范围内，评估哈希分区算法的主要关键点放在第二点上。

#### 哈希取余分区
哈希取余分区的思想类似于java中HashMap命中table的思想，分区命中特别简单：
 >* 计算key的Hash值
 >* 基于节点数量进行取余
 >* 将数据放置到余数指向的节点中
 
这样的命中规则带来的最大的问题就是，每当节点数量发生变化时，所有Hash值得余数都需要重新计算，才能确定该条数据会被分配到哪一个节点上。

#### 一致性分区
一致性分区使用的是环的思想

![一致性分区图示](./.image/一致性分区.webp)

如上图，将hash值按照算法规则做枚举，利用枚举值组成一个环，根据key值计算得到对应的hash值后找到其在环上的位置，之后依据约定好的向前/向后的规则就能得到该值应该附着在哪一个节点上了。

一致性分区能有效的节约节点数量变化的再取余计算，但是一致性分区在中途删除节点的时候容易出现大量值附着在同一个节点的问题。如图，当node2被删除时，对应的数据会被迁移到node4上，造成node4的数据量过大。

#### 带虚拟节点的一致性分区
该方案即为Redis集群采用的数据分区方案

该方案是对一致性分区方案的改进，基本思想不变，只是在原基础上添加了虚拟节点(Redis中的slot)的概念。

槽(slot)可以看作是节点的子集，槽在初始化后数量不允许发生变化，可以有效的减少增删节点带来的数据迁移造成的性能损耗，同时也规避了在删除节点时带来的节点值数量严重不平衡的问题。

引入槽以后，数据的映射关系由数据 hash->实际节点，变成了**数据 hash->槽->实际节点**。在使用了槽的一致性哈希分区中，槽是数据管理和迁移的基本单位。槽解耦了数据和实际节点之间的关系，增加或删除节点对系统的影响很小。槽的数量一般远小于 2^32，远大于实际节点的数量；在 Redis 集群中，槽的数量固定为 16384个。

![槽分配图示](./.image/槽分配.webp)

如上图所示，集群的实际管控者需要调整槽和节点的关系，来保证节点中hash值得稳定性。


[Other](https://mp.weixin.qq.com/s/oDllfcVc5_ekIFP66kRP9w)